---
title: 'Decisions with Multiple Selves: Applications of Social Choice and Game Theory to Decision Theory'
authors: ['admin']
date: '2015-05-27'
publishDate: '2024-09-07T23:10:00.937729Z'
publication_types: ['thesis']

abstract: 'Social choice and game theory are formal tools usually employed to study situations where there are multiple agents present. Game theory is used to model the strategic interactions of a group of individual agents in situations of conflict or cooperation, while social choice theory is concerned with aggregating the preferences or beliefs of a group of individual agents. Both frameworks stand in contrast to decision theory, which studies how an individual agent ought to make rational decisions given its preferences and beliefs. Recent literature, however, suggest the distinction is not so clear-cut and that social choice and game theory can be applied to some situations where only one agent is present. Building on previous results, Lattimore & Hutter (2014) treat sequential decisions as an extensive game with perfect information, and they show that a dynamically consistent agent must achieve a subgame perfect equilibrium against its future selves. Briggs (2010), instead, applies an impossibility theorem from voting theory to show that no decision procedure can meet certain desiderata. This result is achieved by treating the decision-makerâ€™s possible future selves as the voters and candidates of an election. Details aside, the approach of these papers can be described in two steps: representing the decision-maker as a group of agents, existing at different times, each having their own preferences and beliefs; then applying tools usually reserved for multiple agents, such as social choice and game theory, to obtain results about single-agent decisions. This technique has been fruitful and, yet, no one to date has conducted a review of how tools from social choice or game theory can be applied to the decisions of an individual agent. This thesis fills such a gap in the literature, with particular attention to implications for reinforcement learning. The main contribution is to tie together results currently scattered across separate disciplines. Open problems are also identified and discussed.'
---
